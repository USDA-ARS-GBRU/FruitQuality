{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "import transformers\n",
    "from transformers import SegformerFeatureExtractor, SegformerForSemanticSegmentation\n",
    "from datasets import load_metric\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import wandb\n",
    "import sys\n",
    "import random\n",
    "import yaml\n",
    "\n",
    "from transformers.models.segformer.modeling_segformer import BCEWithLogitsLoss, CrossEntropyLoss, SegformerDecodeHead, SegformerModel, SegformerPreTrainedModel, SemanticSegmenterOutput, SegFormerImageClassifierOutput, MSELoss\n",
    "from typing import Optional, Tuple, Union\n",
    "from evaluate import load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# with open('./mtl_segformer_classification.yaml') as file:\n",
    "#     config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "# run = wandb.init(config=config)\n",
    "\n",
    "\n",
    "def normalize_array(arr):\n",
    "    arr_sum = np.sum(arr)\n",
    "    normalized_arr = arr / arr_sum\n",
    "    return normalized_arr\n",
    "\n",
    "\n",
    "DATA_DIR = '/home/mresham/fruitQuality/exports_seeds/Images'\n",
    "MASK_DIR = '/home/mresham/fruitQuality/exports_seeds/Masks'\n",
    "SEED_DATA = '/home/mresham/fruitQuality/exports_seeds/'\n",
    "# wandb_logger = WandbLogger(log_model=False, experiment=run)\n",
    "wandb_logger = WandbLogger(log_model=False, offline=True)\n",
    "MODEL_BASE = \"nvidia/segformer-b0-finetuned-ade-512-512\"\n",
    "# MODEL_BASE = wandb.config.backbone\n",
    "EPOCHS = 2\n",
    "# EPOCHS = wandb.config.epochs\n",
    "WEIGHT = \"None\"\n",
    "MASK_TYPE = \"None\"\n",
    "if WEIGHT == \"None\" or MASK_TYPE == \"None\":\n",
    "    WEIGHTS = None\n",
    "# elif wandb.config.weights != \"None\":\n",
    "#     WEIGHTS = wandb.config.weights\n",
    "else:\n",
    "    MASK_ORDER = ['seed', 'pulp', 'albedo', 'flavedo']\n",
    "    idx = MASK_ORDER.index(MASK_TYPE) + 1\n",
    "    WEIGHTS = np.array([1] * 5)\n",
    "    WEIGHTS[idx] = WEIGHT\n",
    "    WEIGHTS = normalize_array(WEIGHTS)\n",
    "    WEIGHTS = torch.tensor(WEIGHTS, dtype=torch.float32).to(\n",
    "        device=\"cuda\") if WEIGHTS != \"None\" else None\n",
    "LOSS = \"multi\"\n",
    "# LOSS = wandb.config.loss_fct\n",
    "\n",
    "CLF_NUM_LABELS = 30\n",
    "\n",
    "data_ids = ([mask_id.split(\".png\")[0]\n",
    "            for mask_id in os.listdir(SEED_DATA + \"Masks\")])\n",
    "SIZE = len(data_ids)\n",
    "TRAIN_SIZE = int(0.6 * SIZE)\n",
    "VAL_SIZE = int(0.2 * SIZE)  # Also Test size\n",
    "CLASSES = list(reversed(['seed', 'pulp', 'albedo', 'flavedo']))\n",
    "\n",
    "batch_size = 8\n",
    "num_workers = 4\n",
    "# Unsorted Image IDs\n",
    "image_ids = [\n",
    "    \"147\",\n",
    "    \"141\",\n",
    "    \"165\",\n",
    "    \"229\",\n",
    "    \"234\",\n",
    "    \"255\",\n",
    "    \"325\"\n",
    "]\n",
    "# # Sorted Image IDs\n",
    "# image_ids = [\n",
    "#     \"281\",\n",
    "#     \"285\",\n",
    "#     \"291\",\n",
    "#     \"313\",\n",
    "#     \"322\",\n",
    "#     \"345\",\n",
    "#     \"347\"\n",
    "# ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SemanticSegmentationDataset(Dataset):\n",
    "    CLASSES = ['unlabelled', 'seed', 'pulp', 'albedo', 'flavedo']\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            ids,\n",
    "            images_dir,\n",
    "            masks_dir,\n",
    "            classes=None,\n",
    "            feature_extractor=None,\n",
    "            augmentation=None,\n",
    "            preprocessing=None,\n",
    "    ):\n",
    "        self.ids: list = ids\n",
    "        # self.images_fps = [os.path.join(images_dir, image_id.replace(\".png\", \"\"))\n",
    "#                           for image_id in self.ids]\n",
    "        self.images_fps = [os.path.join(\n",
    "            SEED_DATA, \"Images\", f\"{id_}.png\") for id_ in ids]\n",
    "        # self.masks_fps = [os.path.join(\n",
    "        #    masks_dir, image_id) for image_id in self.ids]\n",
    "        self.masks_fps = [os.path.join(\n",
    "            SEED_DATA, \"Masks\", f\"{id_}.png\") for id_ in ids]\n",
    "        self.meta_fps = [os.path.join(\n",
    "            SEED_DATA, \"Images\", f\"{id_}_meta.json\") for id_ in ids]\n",
    "\n",
    "        # convert str names to class values on masks\n",
    "        self.class_values = [self.CLASSES.index(\n",
    "            cls.lower()) for cls in classes]\n",
    "\n",
    "        self.id2label = {}\n",
    "        for i in range(len(classes)):\n",
    "            self.id2label[self.class_values[i]] = classes[i]\n",
    "\n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "        self.feature_extractor = feature_extractor\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        image = Image.open(self.images_fps[i])\n",
    "        segmentation_map = Image.open(self.masks_fps[i])\n",
    "        with open(self.meta_fps[i]) as f:\n",
    "            meta_data = json.load(f)\n",
    "\n",
    "        # randomly crop + pad both image and segmentation map to same size\n",
    "        encoded_inputs = self.feature_extractor(\n",
    "            image, segmentation_map, return_tensors=\"pt\")\n",
    "        encoded_inputs['labels'] //= 51\n",
    "        encoded_inputs['labels'] -= 1\n",
    "        encoded_inputs['seedCount'] = torch.nn.functional.one_hot(\n",
    "            torch.tensor([meta_data['seedCount']]), num_classes=CLF_NUM_LABELS).long()\n",
    "\n",
    "        for k, v in encoded_inputs.items():\n",
    "            encoded_inputs[k].squeeze_()  # remove batch dimension\n",
    "\n",
    "\n",
    "        return encoded_inputs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def get_idx_of_img_id(self, img_id):\n",
    "        try:\n",
    "            return self.ids.index(img_id)\n",
    "        except ValueError:\n",
    "            return -1\n",
    "\n",
    "    def get_image(self, i):\n",
    "        return Image.open(self.images_fps[i])\n",
    "\n",
    "    def get_mask(self, i):\n",
    "        return Image.open(self.masks_fps[i])\n",
    "\n",
    "    def get_nseeds(self, i):\n",
    "        with open(self.meta_fps[i]) as f:\n",
    "            meta_data = json.load(f)\n",
    "        return meta_data['seedCount']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp_dataset = SemanticSegmentationDataset(\n",
    "#     data_ids[:TRAIN_SIZE],\n",
    "#     DATA_DIR,\n",
    "#     MASK_DIR,\n",
    "#     classes=CLASSES,\n",
    "#     feature_extractor=feature_extractor,\n",
    "# )\n",
    "# tmp_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp_data = tmp_dataset[0]\n",
    "# pixel = tmp_data['pixel_values']\n",
    "# labels = tmp_data['labels']\n",
    "# seeds = tmp_data['seedCount']\n",
    "# print(pixel.shape)\n",
    "# print(labels.shape)\n",
    "# print(seeds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp_dataloader = DataLoader(\n",
    "#     tmp_dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "# next(iter(tmp_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FocalLoss_MulticlassDiceLoss(nn.Module):\n",
    "    \"\"\"Multi-class Focal loss implementation.\n",
    "    Args:\n",
    "        gamma (float): The larger the gamma, the smaller\n",
    "            the loss weight of easier samples.\n",
    "        weight (float): A manual rescaling weight given to each\n",
    "            class.\n",
    "        ignore_index (int): Specifies a target value that is ignored\n",
    "            and does not contribute to the input gradient.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes, softmax_dim=None, gamma=2, weight=None, ignore_index=-100, loss=\"multi\"):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.weight = weight\n",
    "        self.ignore_index = ignore_index\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.softmax_dim = softmax_dim\n",
    "        self.loss_fct = loss\n",
    "\n",
    "    def forward(self, input, target, reduction='mean', smooth=1e-6):\n",
    "        if self.loss_fct == \"multi\" or self.loss_fct == \"focal\":\n",
    "            # Focal Loss\n",
    "            logit = F.log_softmax(input, dim=1)\n",
    "            pt = torch.exp(logit)\n",
    "            logit = (1 - pt)**self.gamma * logit\n",
    "            focal_loss = F.nll_loss(\n",
    "                logit, target, self.weight, ignore_index=self.ignore_index)\n",
    "\n",
    "        if self.loss_fct == \"multi\" or self.loss_fct == \"dice\":\n",
    "            targets_one_hot = F.one_hot(\n",
    "                target, num_classes=self.num_classes).permute(0, 3, 1, 2).float()\n",
    "            true_1_hot = targets_one_hot\n",
    "            probas = F.softmax(input, dim=1)\n",
    "            true_1_hot = true_1_hot.type(input.type())\n",
    "            dims = (0,) + tuple(range(2, target.ndimension()))\n",
    "            intersection = torch.sum(probas * true_1_hot, dims)\n",
    "            cardinality = torch.sum(probas + true_1_hot, dims)\n",
    "            dice_coefficient = (2. * intersection /\n",
    "                                (cardinality + smooth)).mean()\n",
    "            dice_loss = -dice_coefficient.log()\n",
    "\n",
    "        total_loss = 0\n",
    "\n",
    "        if self.loss_fct == \"multi\" or self.loss_fct == \"focal\":\n",
    "            total_loss = focal_loss\n",
    "        if self.loss_fct == \"multi\" or self.loss_fct == \"dice\":\n",
    "            total_loss += dice_loss\n",
    "\n",
    "        return total_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SegformerWithDiceLossForSemanticSegmentationAndImageClassification(SegformerPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.segformer = SegformerModel(config)\n",
    "        self.decode_head = SegformerDecodeHead(config)\n",
    "\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        # Classifier head\n",
    "        self.clf_num_labels = CLF_NUM_LABELS\n",
    "        self.classifier = nn.Sequential(nn.Linear(config.hidden_sizes[-1], 256),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Linear(256, 128),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Linear(128, self.clf_num_labels))\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        pixel_values: torch.FloatTensor,\n",
    "        labels: Optional[torch.LongTensor] = None,\n",
    "        seed_count=None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple, SemanticSegmenterOutput, SegFormerImageClassifierOutput]:\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        output_hidden_states = (\n",
    "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
    "        )\n",
    "        print(\"Start forward method\")\n",
    "\n",
    "        outputs = self.segformer(\n",
    "            pixel_values,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=True,  # we need the intermediate hidden states\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        print(\"Got segformer logits\")\n",
    "\n",
    "        encoder_hidden_states = outputs.hidden_states if return_dict else outputs[1]\n",
    "\n",
    "        logits = self.decode_head(encoder_hidden_states)\n",
    "        print(\"Got seg branch logits\")\n",
    "\n",
    "        # Image classification stuff\n",
    "        sequence_output = outputs[0]\n",
    "        # convert last hidden states to (batch_size, height*width, hidden_size)\n",
    "        batch_size = sequence_output.shape[0]\n",
    "\n",
    "        if self.config.reshape_last_stage:\n",
    "            # (batch_size, num_channels, height, width) -> (batch_size, height, width, num_channels)\n",
    "            sequence_output = sequence_output.permute(0, 2, 3, 1)\n",
    "        sequence_output = sequence_output.reshape(\n",
    "            batch_size, -1, self.config.hidden_sizes[-1])\n",
    "        # global average pooling\n",
    "        sequence_output = sequence_output.mean(dim=1)\n",
    "        cl_logits = self.classifier(sequence_output)\n",
    "        print(\"Got classifier branch logits\")\n",
    "        cl_loss = None\n",
    "        # Image classification stuff end\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            # upsample logits to the images' original size\n",
    "            upsampled_logits = nn.functional.interpolate(\n",
    "                logits, size=labels.shape[-2:], mode=\"bilinear\", align_corners=False\n",
    "            )\n",
    "            if self.config.num_labels > 1:\n",
    "                if LOSS == 'cross-entropy':\n",
    "                    loss_fct = CrossEntropyLoss(\n",
    "                        ignore_index=self.config.semantic_loss_ignore_index)\n",
    "                else:\n",
    "                    loss_fct = FocalLoss_MulticlassDiceLoss(\n",
    "                        num_classes=5, weight=WEIGHTS, loss=LOSS)\n",
    "                loss = loss_fct(upsampled_logits, labels)\n",
    "            elif self.config.num_labels == 1:\n",
    "                valid_mask = ((labels >= 0) & (\n",
    "                    labels != self.config.semantic_loss_ignore_index)).float()\n",
    "                loss_fct = BCEWithLogitsLoss(reduction=\"none\")\n",
    "                loss = loss_fct(upsampled_logits.squeeze(1), labels.float())\n",
    "                loss = (loss * valid_mask).mean()\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"Number of labels should be >=0: {self.config.num_labels}\")\n",
    "\n",
    "            # Classification stuff\n",
    "            if self.config.problem_type is None:\n",
    "                if self.clf_num_labels == 1:\n",
    "                    self.config.problem_type = \"regression\"\n",
    "                elif self.clf_num_labels > 1 and (seed_count.dtype == torch.long or seed_count.dtype == torch.int):\n",
    "                    self.config.problem_type = \"single_label_classification\"\n",
    "                else:\n",
    "                    self.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "            if self.config.problem_type == \"regression\":\n",
    "                loss_fct = MSELoss()\n",
    "                if self.clf_num_labels == 1:\n",
    "                    cl_loss = loss_fct(cl_logits.squeeze(),\n",
    "                                       seed_count.squeeze().float())\n",
    "                else:\n",
    "                    cl_loss = loss_fct(cl_logits, seed_count)\n",
    "            elif self.config.problem_type == \"single_label_classification\":\n",
    "                print('single_label_classification')  # TODO remove later\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                print(cl_logits.view(-1, self.clf_num_labels).size())\n",
    "                print(seed_count.view(-1, self.clf_num_labels).size())\n",
    "                cl_loss = loss_fct(\n",
    "                    cl_logits.view(-1, self.clf_num_labels), seed_count.view(-1, self.clf_num_labels).float())\n",
    "            elif self.config.problem_type == \"multi_label_classification\":\n",
    "                loss_fct = BCEWithLogitsLoss()\n",
    "                cl_loss = loss_fct(cl_logits, seed_count)\n",
    "            # Image classification stuff end\n",
    "\n",
    "        print(\"Stop forward method\")\n",
    "        if not return_dict:\n",
    "            if output_hidden_states:\n",
    "                output = (logits,) + outputs[1:]\n",
    "            else:\n",
    "                output = (logits,) + outputs[2:]\n",
    "            seg_return = ((loss,) + output) if loss is not None else output\n",
    "\n",
    "            # Classification Stuff\n",
    "            cl_output = (cl_logits,) + outputs[1:]\n",
    "            cl_return = (\n",
    "                (cl_loss,) + cl_output) if loss is not None else cl_output\n",
    "\n",
    "            return (seg_return, cl_return)\n",
    "\n",
    "        return (SemanticSegmenterOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states if output_hidden_states else None,\n",
    "            attentions=outputs.attentions,\n",
    "        ), SegFormerImageClassifierOutput(\n",
    "            loss=cl_loss,\n",
    "            logits=cl_logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MTLSegformerFinetuner(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, id2label, train_dataloader=None, val_dataloader=None, test_dataloader=None, metrics_interval=100):\n",
    "        super(MTLSegformerFinetuner, self).__init__()\n",
    "        id2label[0] = 'Unlabeled'\n",
    "        self.id2label = id2label\n",
    "        self.metrics_interval = metrics_interval\n",
    "        self.train_dl = train_dataloader\n",
    "        self.val_dl = val_dataloader\n",
    "        self.test_dl = test_dataloader\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.num_classes = len(id2label.keys())\n",
    "        self.label2id = {v: k for k, v in self.id2label.items()}\n",
    "\n",
    "        self.model = SegformerWithDiceLossForSemanticSegmentationAndImageClassification.from_pretrained(\n",
    "            MODEL_BASE,\n",
    "            return_dict=False,\n",
    "            num_labels=self.num_classes,\n",
    "            id2label=self.id2label,\n",
    "            label2id=self.label2id,\n",
    "            ignore_mismatched_sizes=True,\n",
    "        )\n",
    "\n",
    "        self.train_mean_iou = load(\"mean_iou\")\n",
    "        self.val_mean_iou = load(\"mean_iou\")\n",
    "        self.test_mean_iou = load(\"mean_iou\")\n",
    "\n",
    "        self.train_mse = load(\"mse\")\n",
    "        self.val_mse = load(\"mse\")\n",
    "        self.test_mse = load(\"mse\")\n",
    "\n",
    "        self.test_mae = load(\"mae\")\n",
    "        self.test_corr = load(\"pearsonr\")\n",
    "\n",
    "        self.validation_step_outputs = []\n",
    "        self.test_step_outputs = []\n",
    "\n",
    "    def forward(self, images, masks, seed_count):\n",
    "        print(\"Start Pylight mod\")\n",
    "        seg_outputs, clf_outputs = self.model(\n",
    "            pixel_values=images, labels=masks, seed_count=seed_count)\n",
    "        print(\"Stop Pylight mod\")\n",
    "        return (seg_outputs, clf_outputs)\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "\n",
    "        images, masks, seed_count = batch['pixel_values'], batch['labels'], batch['seedCount']\n",
    "\n",
    "        seg_outputs, clf_outputs = self(images, masks, seed_count)\n",
    "\n",
    "        loss, logits = seg_outputs[0], seg_outputs[1]\n",
    "        clf_loss, clf_logits = clf_outputs[0], clf_outputs[1]\n",
    "        total_loss = torch.add(loss, clf_loss)\n",
    "\n",
    "        upsampled_logits = nn.functional.interpolate(\n",
    "            logits,\n",
    "            size=masks.shape[-2:],\n",
    "            mode=\"bilinear\",\n",
    "            align_corners=False\n",
    "        )\n",
    "\n",
    "        predicted = upsampled_logits.argmax(dim=1)\n",
    "\n",
    "        self.train_mean_iou.add_batch(\n",
    "            predictions=predicted.detach().cpu().numpy(),\n",
    "            references=masks.detach().cpu().numpy()\n",
    "        )\n",
    "        self.train_mse.add_batch(\n",
    "            predictions=clf_logits.detach().cpu().numpy().argmax(axis=1).tolist(),\n",
    "            references=seed_count.detach().cpu().numpy().argmax(axis=1).tolist()\n",
    "        )\n",
    "        if batch_nb % self.metrics_interval == 0:\n",
    "\n",
    "            metrics = self.train_mean_iou.compute(\n",
    "                num_labels=self.num_classes,\n",
    "                ignore_index=255,\n",
    "                reduce_labels=False,\n",
    "            )\n",
    "            mse = self.train_mse.compute()['mse']\n",
    "\n",
    "            metrics = {'loss': total_loss,\n",
    "                       \"mean_iou\": metrics[\"mean_iou\"], \"mean_accuracy\": metrics[\"mean_accuracy\"], \"mse\": mse}\n",
    "\n",
    "            for k, v in metrics.items():\n",
    "                self.log(k, v, prog_bar=True)\n",
    "\n",
    "            return (metrics)\n",
    "        else:\n",
    "            return ({'loss': total_loss})\n",
    "\n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        print(\"Start valid step\")\n",
    "\n",
    "        images, masks, seed_count = batch['pixel_values'], batch['labels'], batch['seedCount']\n",
    "\n",
    "        seg_outputs, clf_outputs = self(images, masks, seed_count)\n",
    "\n",
    "        loss, logits = seg_outputs[0], seg_outputs[1]\n",
    "        clf_loss, clf_logits = clf_outputs[0], clf_outputs[1]\n",
    "        total_loss = torch.add(loss, clf_loss)\n",
    "\n",
    "        upsampled_logits = nn.functional.interpolate(\n",
    "            logits,\n",
    "            size=masks.shape[-2:],\n",
    "            mode=\"bilinear\",\n",
    "            align_corners=False\n",
    "        )\n",
    "\n",
    "        predicted = upsampled_logits.argmax(dim=1)\n",
    "\n",
    "        self.val_mean_iou.add_batch(\n",
    "            predictions=predicted.detach().cpu().numpy(),\n",
    "            references=masks.detach().cpu().numpy()\n",
    "        )\n",
    "        self.val_mse.add_batch(\n",
    "            predictions=clf_logits.detach().cpu().numpy().argmax(axis=1).tolist(),\n",
    "            references=seed_count.detach().cpu().numpy().argmax(axis=1).tolist()\n",
    "        )\n",
    "\n",
    "        self.validation_step_outputs.append(total_loss)\n",
    "\n",
    "        print(\"Stop valid step\")\n",
    "        return ({'val_loss': total_loss})\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        outputs = self.validation_step_outputs\n",
    "        metrics = self.val_mean_iou.compute(\n",
    "            num_labels=self.num_classes,\n",
    "            ignore_index=255,\n",
    "            reduce_labels=False,\n",
    "        )\n",
    "        mse = self.val_mse.compute()['mse']\n",
    "\n",
    "        avg_val_loss = torch.stack(outputs).mean()\n",
    "        val_mean_iou = metrics[\"mean_iou\"]\n",
    "        val_mean_accuracy = metrics[\"mean_accuracy\"]\n",
    "        val_per_category_iou = metrics['per_category_iou']\n",
    "\n",
    "        metrics = {\"val_loss\": avg_val_loss, \"val_mean_iou\": val_mean_iou,\n",
    "                   \"val_mean_accuracy\": val_mean_accuracy, \"val_mean_mse\": mse}\n",
    "        for i in self.id2label.keys():\n",
    "            metrics[f\"val_{self.id2label[i]}_iou\"] = val_per_category_iou[i]\n",
    "\n",
    "        for k, v in metrics.items():\n",
    "            self.log(k, v, prog_bar=True)\n",
    "\n",
    "        self.validation_step_outputs.clear()\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    def test_step(self, batch, batch_nb):\n",
    "\n",
    "        images, masks, seed_count = batch['pixel_values'], batch['labels'], batch['seedCount']\n",
    "\n",
    "        seg_outputs, clf_outputs = self(images, masks, seed_count)\n",
    "\n",
    "        loss, logits = seg_outputs[0], seg_outputs[1]\n",
    "        clf_loss, clf_logits = clf_outputs[0], clf_outputs[1]\n",
    "        total_loss = torch.add(loss, clf_loss)\n",
    "\n",
    "        upsampled_logits = nn.functional.interpolate(\n",
    "            logits,\n",
    "            size=masks.shape[-2:],\n",
    "            mode=\"bilinear\",\n",
    "            align_corners=False\n",
    "        )\n",
    "\n",
    "        predicted = upsampled_logits.argmax(dim=1)\n",
    "\n",
    "        self.test_mean_iou.add_batch(\n",
    "            predictions=predicted.detach().cpu().numpy(),\n",
    "            references=masks.detach().cpu().numpy()\n",
    "        )\n",
    "        self.test_mse.add_batch(\n",
    "            predictions=clf_logits.detach().cpu().numpy().argmax(axis=1).tolist(),\n",
    "            references=seed_count.detach().cpu().numpy().argmax(axis=1).tolist()\n",
    "        )\n",
    "        self.test_mae.add_batch(\n",
    "            predictions=clf_logits.detach().cpu().numpy().argmax(axis=1).tolist(),\n",
    "            references=seed_count.detach().cpu().numpy().argmax(axis=1).tolist()\n",
    "        )\n",
    "        self.test_corr.add_batch(\n",
    "            predictions=clf_logits.detach().cpu().numpy().argmax(axis=1).tolist(),\n",
    "            references=seed_count.detach().cpu().numpy().argmax(axis=1).tolist()\n",
    "        )\n",
    "\n",
    "        self.test_step_outputs.append(total_loss)\n",
    "\n",
    "        return ({'test_loss': total_loss})\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        outputs = self.test_step_outputs\n",
    "        metrics = self.test_mean_iou.compute(\n",
    "            num_labels=self.num_classes,\n",
    "            ignore_index=255,\n",
    "            reduce_labels=False,\n",
    "        )\n",
    "\n",
    "        avg_test_loss = torch.stack(outputs).mean()\n",
    "        test_mean_iou = metrics[\"mean_iou\"]\n",
    "        test_mean_accuracy = metrics[\"mean_accuracy\"]\n",
    "        test_per_category_iou = metrics['per_category_iou']\n",
    "        mse = self.test_mse.compute()['mse']\n",
    "        mae = self.test_mae.compute()['mae']\n",
    "        corr = self.test_corr.compute()['pearsonr']\n",
    "\n",
    "        metrics = {\"test_loss\": avg_test_loss, \"test_mean_iou\": test_mean_iou,\n",
    "                   \"test_mean_accuracy\": test_mean_accuracy, \"test_mean_mse\": mse,\n",
    "                   \"test_mean_mae\": mae, \"test_mean_corr\": corr}\n",
    "        for i in self.id2label.keys():\n",
    "            metrics[f\"test_{self.id2label[i]}_iou\"] = test_per_category_iou[i]\n",
    "\n",
    "        for k, v in metrics.items():\n",
    "            self.log(k, v, prog_bar=True)\n",
    "\n",
    "        self.test_step_outputs.clear()\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam([p for p in self.parameters() if p.requires_grad], lr=2e-05, eps=1e-08)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self.train_dl\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.val_dl\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self.test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_extractor = SegformerFeatureExtractor.from_pretrained(\n",
    "    MODEL_BASE)\n",
    "feature_extractor.reduce_labels = False\n",
    "feature_extractor.size = 128\n",
    "\n",
    "\n",
    "train_dataset = SemanticSegmentationDataset(\n",
    "    data_ids[:TRAIN_SIZE],\n",
    "    DATA_DIR,\n",
    "    MASK_DIR,\n",
    "    classes=CLASSES,\n",
    "    feature_extractor=feature_extractor,\n",
    ")\n",
    "val_dataset = SemanticSegmentationDataset(\n",
    "    data_ids[TRAIN_SIZE:TRAIN_SIZE+VAL_SIZE],\n",
    "    DATA_DIR,\n",
    "    MASK_DIR,\n",
    "    classes=CLASSES,\n",
    "    feature_extractor=feature_extractor,\n",
    ")\n",
    "test_dataset = SemanticSegmentationDataset(\n",
    "    data_ids[TRAIN_SIZE+VAL_SIZE:],\n",
    "    DATA_DIR,\n",
    "    MASK_DIR,\n",
    "    classes=CLASSES,\n",
    "    feature_extractor=feature_extractor,\n",
    ")\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset, batch_size=batch_size, num_workers=num_workers)\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "mtl_segformer_finetuner = MTLSegformerFinetuner(\n",
    "    train_dataset.id2label,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    metrics_interval=10,\n",
    ")\n",
    "\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0.00,\n",
    "    patience=10,\n",
    "    verbose=False,\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(save_top_k=1, monitor=\"val_loss\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator='gpu',\n",
    "    callbacks=[checkpoint_callback],\n",
    "    max_epochs=EPOCHS,\n",
    "    logger=wandb_logger,\n",
    "    val_check_interval=len(train_dataloader),\n",
    "    log_every_n_steps=1\n",
    ")\n",
    "# wandb_logger.experiment.config.update({\"model\": MODEL_BASE})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainer.fit(mtl_segformer_finetuner)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at ./lightning_logs/eqdg94tr/checkpoints/epoch=1-step=50.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7,8,9]\n",
      "Loaded model weights from the checkpoint at ./lightning_logs/eqdg94tr/checkpoints/epoch=1-step=50.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0:   0%|          | 0/9 [00:00<?, ?it/s]Start Pylight mod\n",
      "Start forward method\n",
      "Got segformer logits\n",
      "Got seg branch logits\n",
      "Got classifier branch logits\n",
      "single_label_classification\n",
      "torch.Size([8, 30])\n",
      "torch.Size([8, 30])\n",
      "Stop forward method\n",
      "Stop Pylight mod\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mresham/fruitQuality/venvTorch/lib/python3.8/site-packages/datasets/features/image.py:334: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n",
      "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0:  11%|█         | 1/9 [00:02<00:16,  0.48it/s]Start Pylight mod\n",
      "Start forward method\n",
      "Got segformer logits\n",
      "Got seg branch logits\n",
      "Got classifier branch logits\n",
      "single_label_classification\n",
      "torch.Size([8, 30])\n",
      "torch.Size([8, 30])\n",
      "Stop forward method\n",
      "Stop Pylight mod\n",
      "Testing DataLoader 0:  22%|██▏       | 2/9 [00:02<00:07,  0.94it/s]Start Pylight mod\n",
      "Start forward method\n",
      "Got segformer logits\n",
      "Got seg branch logits\n",
      "Got classifier branch logits\n",
      "single_label_classification\n",
      "torch.Size([8, 30])\n",
      "torch.Size([8, 30])\n",
      "Stop forward method\n",
      "Stop Pylight mod\n",
      "Testing DataLoader 0:  33%|███▎      | 3/9 [00:02<00:04,  1.38it/s]Start Pylight mod\n",
      "Start forward method\n",
      "Got segformer logits\n",
      "Got seg branch logits\n",
      "Got classifier branch logits\n",
      "single_label_classification\n",
      "torch.Size([8, 30])\n",
      "torch.Size([8, 30])\n",
      "Stop forward method\n",
      "Stop Pylight mod\n",
      "Testing DataLoader 0:  44%|████▍     | 4/9 [00:02<00:02,  1.81it/s]Start Pylight mod\n",
      "Start forward method\n",
      "Got segformer logits\n",
      "Got seg branch logits\n",
      "Got classifier branch logits\n",
      "single_label_classification\n",
      "torch.Size([8, 30])\n",
      "torch.Size([8, 30])\n",
      "Stop forward method\n",
      "Stop Pylight mod\n",
      "Testing DataLoader 0:  56%|█████▌    | 5/9 [00:02<00:01,  2.23it/s]Start Pylight mod\n",
      "Start forward method\n",
      "Got segformer logits\n",
      "Got seg branch logits\n",
      "Got classifier branch logits\n",
      "single_label_classification\n",
      "torch.Size([8, 30])\n",
      "torch.Size([8, 30])\n",
      "Stop forward method\n",
      "Stop Pylight mod\n",
      "Testing DataLoader 0:  67%|██████▋   | 6/9 [00:02<00:01,  2.64it/s]Start Pylight mod\n",
      "Start forward method\n",
      "Got segformer logits\n",
      "Got seg branch logits\n",
      "Got classifier branch logits\n",
      "single_label_classification\n",
      "torch.Size([8, 30])\n",
      "torch.Size([8, 30])\n",
      "Stop forward method\n",
      "Stop Pylight mod\n",
      "Testing DataLoader 0:  78%|███████▊  | 7/9 [00:02<00:00,  3.05it/s]Start Pylight mod\n",
      "Start forward method\n",
      "Got segformer logits\n",
      "Got seg branch logits\n",
      "Got classifier branch logits\n",
      "single_label_classification\n",
      "torch.Size([8, 30])\n",
      "torch.Size([8, 30])\n",
      "Stop forward method\n",
      "Stop Pylight mod\n",
      "Testing DataLoader 0:  89%|████████▉ | 8/9 [00:02<00:00,  3.44it/s]Start Pylight mod\n",
      "Start forward method\n",
      "Got segformer logits\n",
      "Got seg branch logits\n",
      "Got classifier branch logits\n",
      "single_label_classification\n",
      "torch.Size([4, 30])\n",
      "torch.Size([4, 30])\n",
      "Stop forward method\n",
      "Stop Pylight mod\n",
      "Testing DataLoader 0: 100%|██████████| 9/9 [00:02<00:00,  3.53it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    test_Unlabeled_iou     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.19129383003641437    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_albedo_iou      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.0013421828908554573   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_flavedo_iou      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6829032788671257     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     5.260339736938477     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    test_mean_accuracy     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4214805850259692     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_mean_corr       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.25304415822029114    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_mean_iou       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.32431432392363496    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_mean_mae       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     2.264705882352941     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_mean_mse       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    18.705882352941178     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_pulp_iou       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6634140958482907     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_seed_iou       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0826182319754887     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m   test_Unlabeled_iou    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.19129383003641437   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_albedo_iou     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0013421828908554573  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_flavedo_iou     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6829032788671257    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    5.260339736938477    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   test_mean_accuracy    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4214805850259692    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_mean_corr      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.25304415822029114   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_mean_iou      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.32431432392363496   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_mean_mae      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    2.264705882352941    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_mean_mse      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   18.705882352941178    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_pulp_iou      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6634140958482907    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_seed_iou      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0826182319754887    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start forward method\n",
      "Got segformer logits\n",
      "Got seg branch logits\n",
      "Got classifier branch logits\n",
      "single_label_classification\n",
      "torch.Size([1, 30])\n",
      "torch.Size([1, 30])\n",
      "Stop forward method\n",
      "Start forward method\n",
      "Got segformer logits\n",
      "Got seg branch logits\n",
      "Got classifier branch logits\n",
      "single_label_classification\n",
      "torch.Size([1, 30])\n",
      "torch.Size([1, 30])\n",
      "Stop forward method\n",
      "Start forward method\n",
      "Got segformer logits\n",
      "Got seg branch logits\n",
      "Got classifier branch logits\n",
      "single_label_classification\n",
      "torch.Size([1, 30])\n",
      "torch.Size([1, 30])\n",
      "Stop forward method\n",
      "Start forward method\n",
      "Got segformer logits\n",
      "Got seg branch logits\n",
      "Got classifier branch logits\n",
      "single_label_classification\n",
      "torch.Size([1, 30])\n",
      "torch.Size([1, 30])\n",
      "Stop forward method\n",
      "Start forward method\n",
      "Got segformer logits\n",
      "Got seg branch logits\n",
      "Got classifier branch logits\n",
      "single_label_classification\n",
      "torch.Size([1, 30])\n",
      "torch.Size([1, 30])\n",
      "Stop forward method\n",
      "Start forward method\n",
      "Got segformer logits\n",
      "Got seg branch logits\n",
      "Got classifier branch logits\n",
      "single_label_classification\n",
      "torch.Size([1, 30])\n",
      "torch.Size([1, 30])\n",
      "Stop forward method\n",
      "Start forward method\n",
      "Got segformer logits\n",
      "Got seg branch logits\n",
      "Got classifier branch logits\n",
      "single_label_classification\n",
      "torch.Size([1, 30])\n",
      "torch.Size([1, 30])\n",
      "Stop forward method\n"
     ]
    }
   ],
   "source": [
    "\n",
    "res = trainer.test(ckpt_path=\"best\")\n",
    "mtl_segformer_finetuner = mtl_segformer_finetuner.to(device=\"cuda\")\n",
    "\n",
    "\n",
    "def run_sample_output(img_id):\n",
    "    idx_in_test_set = test_dataset.get_idx_of_img_id(img_id)\n",
    "    if idx_in_test_set == -1:\n",
    "        return None\n",
    "    dataset_image = test_dataset.get_image(idx_in_test_set)\n",
    "    encoded_inputs = test_dataset[idx_in_test_set]\n",
    "    images, masks, seed_count = encoded_inputs['pixel_values'], encoded_inputs['labels'], encoded_inputs['seedCount']\n",
    "    # outputs = segformer_finetuner.model(images.unsqueeze(0), masks.unsqueeze(0))\n",
    "    images, masks, seed_count = images.to(device=\"cuda\"), masks.to(\n",
    "        device=\"cuda\"), seed_count.to(device=\"cuda\")\n",
    "    seg_outputs, clf_outputs = mtl_segformer_finetuner.model(\n",
    "        images.unsqueeze(0), masks.unsqueeze(0), seed_count.unsqueeze(0))\n",
    "\n",
    "    _, logits = seg_outputs[0], seg_outputs[1]\n",
    "    _, clf_logits = clf_outputs[0], clf_outputs[1]\n",
    "\n",
    "    # Seed Count outputs\n",
    "    my_data = [img_id,\n",
    "               str(seed_count.detach().cpu().numpy()),\n",
    "               str(clf_logits.detach().cpu().numpy())]\n",
    "\n",
    "    # Mask outptus\n",
    "    # First, rescale logits to original image size\n",
    "    upsampled_logits = nn.functional.interpolate(logits,\n",
    "                                                 # (height, width)\n",
    "                                                 size=dataset_image.size[::-1],\n",
    "                                                 mode='bilinear',\n",
    "                                                 align_corners=False)\n",
    "\n",
    "    # Second, apply argmax on the class dimension\n",
    "    seg = upsampled_logits.argmax(dim=1).cpu().numpy()[0]\n",
    "\n",
    "    # wandb_image = wandb.Image(dataset_image, caption=\"Input image\")\n",
    "    wandb_logger.log_image(\n",
    "        img_id, [dataset_image], caption=[\"Input image\"])\n",
    "\n",
    "    # Change pixel order to be seed, pulp, albedo, flavedo, background\n",
    "    ground_truth_mask = (\n",
    "        np.array(test_dataset.get_mask(idx_in_test_set)) // 51)\n",
    "    tmp_gt_mask = ground_truth_mask + 10\n",
    "    # Dont change order here\n",
    "    tmp_gt_mask = np.where(tmp_gt_mask == 10, 4, tmp_gt_mask)\n",
    "    tmp_gt_mask = np.where(tmp_gt_mask == 14, 0, tmp_gt_mask)\n",
    "    tmp_gt_mask = np.where(tmp_gt_mask == 13, 1, tmp_gt_mask)\n",
    "    tmp_gt_mask = np.where(tmp_gt_mask == 12, 2, tmp_gt_mask)\n",
    "    tmp_gt_mask = np.where(tmp_gt_mask == 11, 3, tmp_gt_mask)\n",
    "    ground_truth_mask = tmp_gt_mask\n",
    "    wandb_logger.log_image(img_id, [dataset_image], caption=[\"True Masks\"],\n",
    "                           masks=[{\n",
    "                               \"ground_truth\": {\n",
    "                                   \"mask_data\": ground_truth_mask.squeeze(),\n",
    "                                   \"class_labels\": {4: \"Background\",\n",
    "                                                    0: \"Seed\",\n",
    "                                                    1: \"Pulp\",\n",
    "                                                    2: \"Albedo\",\n",
    "                                                    3: \"Flavedo\"\n",
    "                                                    }\n",
    "                               }}\n",
    "    ])\n",
    "\n",
    "    # Change pixel order to be Background, seed, pulp, albedo, flavedo\n",
    "    # tmp_seg = seg + 1\n",
    "    # seg = np.where(tmp_seg == 5, 0, tmp_seg)\n",
    "    wandb_logger.log_image(img_id, [dataset_image], caption=[\"Predicted Masks\"],\n",
    "                           masks=[{\n",
    "                               \"predicted_mask\": {\n",
    "                                   \"mask_data\": seg.squeeze(),\n",
    "                                   \"class_labels\": {\n",
    "                                       0: \"Seed\",\n",
    "                                       1: \"Pulp\",\n",
    "                                       2: \"Albedo\",\n",
    "                                       3: \"Flavedo\",\n",
    "                                       4: \"Background\",\n",
    "                                   }\n",
    "                               }}\n",
    "    ])\n",
    "\n",
    "    return my_data\n",
    "\n",
    "\n",
    "columns = [\"image id\", \"seed label\", \"seed prediction\"]\n",
    "seed_count_data = []\n",
    "for img_id in image_ids:\n",
    "    seed_data = run_sample_output(img_id)\n",
    "    if seed_data:\n",
    "        seed_count_data.append(seed_data)\n",
    "\n",
    "# using columns and data\n",
    "wandb_logger.log_text(key=\"Seed Count\", columns=columns, data=seed_count_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
